import numpy as np
import json
import os
import cv2
import torch
from PIL import Image
from datetime import timedelta

# ==========================================
# 1. æ¨¡å‹åŠ è½½åŒº (æ ¹æ®ç¡¬ä»¶é€‰æ‹©)
# ==========================================

# --- [Mac M3 Pro æ–¹æ¡ˆ] SigLIP (Google SOTA, ä¼˜äº CLIP) ---
from transformers import AutoProcessor, AutoModel
MODEL_ID = "google/siglip-so400m-patch14-384"
device = "mps" if torch.backends.mps.is_available() else "cpu"
print(f"ğŸš€ æ­£åœ¨ä½¿ç”¨ Mac åŠ é€Ÿè®¾å¤‡: {device}")

# åŠ è½½æ¨¡å‹
model = AutoModel.from_pretrained(MODEL_ID).to(device)
processor = AutoProcessor.from_pretrained(MODEL_ID)

# --- [CUDA / Linux æ–¹æ¡ˆ] InternVideo2.5 (ä»…ä¾›å‚è€ƒï¼Œå–æ¶ˆæ³¨é‡Šä½¿ç”¨) ---
# """
# import torch
# from transformers import AutoModel, AutoProcessor
# MODEL_ID = "OpenGVLab/InternVideo2-5-1B"
# device = "cuda"
# model = AutoModel.from_pretrained(MODEL_ID, trust_remote_code=True).to(device)
# # æ³¨æ„: InternVideo éœ€è¦ç‰¹å®šçš„é¢„å¤„ç†å‡½æ•°ï¼Œé€šå¸¸éœ€ clone å®˜æ–¹ repo
# """

# ==========================================
# 2. é…ç½®è·¯å¾„
# ==========================================
BASE_DIR = "/home/SONY/s7000043396/Downloads/demo/script"
MOSAIC_VIDEO = os.path.join(BASE_DIR, "mosaic_preview_720p.mp4")
FEATURE_FILE = os.path.join(BASE_DIR, "Mosaic_preview_features.npy")
METADATA_FILE = os.path.join(BASE_DIR, "feature_metadata.json")

def extract_features():
    print(f"--- å¼€å§‹æå–ç‰¹å¾ (Model: {MODEL_ID}) ---")
    
    cap = cv2.VideoCapture(MOSAIC_VIDEO)
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = int(frame_count / fps)
    
    features_list = []
    metadata = []
    
    print(f"è§†é¢‘æ€»æ—¶é•¿: {duration} ç§’. é‡‡æ ·ç‡: 1 fps")

    for t in range(duration):
        # ç²¾å‡†è·³è½¬åˆ°ç¬¬ t ç§’
        cap.set(cv2.CAP_PROP_POS_MSEC, t * 1000)
        ret, frame = cap.read()
        if not ret: break
        
        # BGR -> RGB
        image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        
        # ==========================================
        # æ¨ç†é€»è¾‘ (Mac Active)
        # ==========================================
        inputs = processor(images=image, return_tensors="pt").to(device)
        with torch.no_grad():
            # SigLIP æå–å›¾åƒç‰¹å¾
            image_features = model.get_image_features(**inputs)
            # å½’ä¸€åŒ– (ä¾¿äºåç»­è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦)
            image_features = image_features / image_features.norm(p=2, dim=-1, keepdim=True)
            
        features_list.append(image_features.cpu().numpy())

        # ==========================================
        # æ¨ç†é€»è¾‘ (CUDA Option - Commented)
        # ==========================================
        # inputs = preprocess_internvideo(frame).to(device)
        # with torch.no_grad():
        #     feat = model.encode_video(inputs)
        #     features_list.append(feat.cpu().numpy())

        # æ„å»ºå…ƒæ•°æ®
        metadata.append({
            "timestamp_sec": t,
            "ltc": f"14:00:{t:02d}:00", # æ¨¡æ‹Ÿ 2026 å·¥ä¸šçº§ LTC
            "grid_layout": "4x2"
        })
        
        if t % 10 == 0:
            print(f"å·²å¤„ç† {t}/{duration} ç§’...")

    cap.release()
    
    # ä¿å­˜ç»“æœ
    if features_list:
        final_matrix = np.vstack(features_list)
        np.save(FEATURE_FILE, final_matrix)
        with open(METADATA_FILE, "w") as f:
            json.dump(metadata, f, indent=4)
        print(f"âœ… ç‰¹å¾æå–å®Œæˆ! çŸ©é˜µå½¢çŠ¶: {final_matrix.shape}")
    else:
        print("âŒ é”™è¯¯: æœªæå–åˆ°ä»»ä½•ç‰¹å¾")

if __name__ == "__main__":
    extract_features()