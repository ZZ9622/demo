import numpy as np
import json
import os
import opentimelineio as otio
import cv2
import re

# ==========================================
# 1. æ¨¡å‹åŠ è½½åŒº (Mac MLX vs CUDA vLLM)
# ==========================================

# --- [Mac M3 Pro æ–¹æ¡ˆ] MLX (Apple Silicon ä¸“ç”¨åŠ é€Ÿ) ---
# è‡ªåŠ¨ä¸‹è½½å¹¶åŠ è½½ 4-bit é‡åŒ–ç‰ˆ Qwen2-VLï¼Œæ˜¾å­˜ä»…éœ€ ~6GB
from mlx_vlm import load, generate
from mlx_vlm.utils import load_image
MODEL_PATH = "mlx-community/Qwen2-VL-7B-Instruct-4bit"
print(f"ğŸš€ æ­£åœ¨åŠ è½½ Mac MLX æ¨¡å‹: {MODEL_PATH}")
model, processor = load(MODEL_PATH, trust_remote_code=True)

# --- [CUDA / Linux æ–¹æ¡ˆ] vLLM (æœåŠ¡å™¨çº§è¶…å¿«æ¨ç†) ---
# """
# from vllm import LLM, SamplingParams
# MODEL_PATH = "Qwen/Qwen2-VL-7B-Instruct"
# print("æ­£åœ¨åŠ è½½ CUDA vLLM æ¨¡å‹...")
# model = LLM(model=MODEL_PATH, quantization=None, enforce_eager=True)
# sampling_params = SamplingParams(temperature=0.1, max_tokens=50)
# """

# ==========================================
# 2. é…ç½®ä¸å·¥å…·å‡½æ•°
# ==========================================
BASE_DIR = "/home/SONY/s7000043396/Downloads/demo/script"
DATA_DIR = "/home/SONY/s7000043396/Downloads/demo/data/demo-data"
MOSAIC_VIDEO = os.path.join(BASE_DIR, "mosaic_preview_720p.mp4")

def get_best_camera_ai(timestamp_sec, user_prompt):
    """
    æ ¸å¿ƒå†³ç­–å‡½æ•°ï¼šæˆªå–è¯¥ç§’çš„ç”»é¢ -> é€å…¥ VL å¤§æ¨¡å‹ -> è§£ææœ€ä½³æœºä½
    """
    # 1. ä»è§†é¢‘ä¸­æˆªå–ä¸€å¸§å›¾ç‰‡
    cap = cv2.VideoCapture(MOSAIC_VIDEO)
    cap.set(cv2.CAP_PROP_POS_MSEC, timestamp_sec * 1000)
    ret, frame = cap.read()
    cap.release()
    
    if not ret: return 0 # Fallback
    
    temp_img_path = os.path.join(BASE_DIR, "temp_inference.jpg")
    cv2.imwrite(temp_img_path, frame)

    # 2. æ„å»ºå¤šæ¨¡æ€ Prompt (æ•™ä¼š AI æ€ä¹ˆçœ‹ 4x2 å¸ƒå±€)
    prompt_text = f"""
    Below is a mosaic view of 8 cameras covering a basketball game.
    Layout:
    [Cam 0] [Cam 1] [Cam 2] [Cam 3]
    [Cam 4] [Cam 5] [Cam 6] [Cam 7]

    User Request: "{user_prompt}"

    Task: Identify which SINGLE camera ID (0-7) captures the action described best.
    Criteria: Clear view, no obstruction, good composition.
    Output: Return ONLY the camera ID number (e.g., 5). Do not explain.
    """

    # ==========================================
    # æ¨ç†é€»è¾‘ (Mac Active)
    # ==========================================
    response = generate(
        model, 
        processor, 
        image=temp_img_path, 
        prompt=prompt_text, 
        max_tokens=10, 
        verbose=False
    )
    
    # ==========================================
    # æ¨ç†é€»è¾‘ (CUDA Option - Commented)
    # ==========================================
    # """
    # inputs = [{"prompt": prompt_text, "multi_modal_data": {"image": frame}}]
    # outputs = model.generate(inputs, sampling_params)
    # response = outputs[0].outputs[0].text
    # """

    # 3. è§£æç»“æœ (æå–æ•°å­—)
    try:
        # ä½¿ç”¨æ­£åˆ™æ‰¾æ•°å­—
        best_cam = int(re.search(r'\d+', response).group())
        return max(0, min(7, best_cam)) # é™åˆ¶åœ¨ 0-7
    except:
        print(f"âš ï¸ AI è¾“å‡ºæ— æ³•è§£æ: '{response}'ï¼Œé»˜è®¤ä½¿ç”¨æœºä½ 0")
        return 0

def run_pipeline(user_prompt):
    print(f"--- æ”¶åˆ°å¯¼æ’­æŒ‡ä»¤: {user_prompt} ---")
    
    # åŠ è½½å¸ƒå±€
    with open(os.path.join(BASE_DIR, "Camera_Layout.json"), "r") as f:
        layout = json.load(f)
        
    # [æ¨¡æ‹Ÿæ£€ç´¢å±‚] å‡è®¾ VideoChat å·²ç»å¸®æˆ‘ä»¬æ‰¾åˆ°äº†å‡ ä¸ªå…³é”®æ—¶é—´ç‚¹
    # å®é™…é¡¹ç›®ä¸­ï¼Œè¿™é‡Œåº”è¯¥å…ˆç”¨ 02 çš„ç‰¹å¾å»æœç´¢ features.npy
    # è¿™é‡Œä¸ºäº†æ¼”ç¤º 03 çš„æ ¸å¿ƒèƒ½åŠ›ï¼Œæˆ‘ä»¬ç¡¬ç¼–ç äº†ä¸¤ä¸ªç²¾å½©æ—¶åˆ»
    candidate_timestamps = [2, 10] # å‡è®¾ç¬¬2ç§’å’Œç¬¬10ç§’æœ‰ç²¾å½©é•œå¤´

    # åˆ›å»º OTIO æ—¶é—´è½´
    timeline = otio.schema.Timeline(name="AI_Mac_Edit")
    track = otio.schema.Track(name="Main_Sequence")
    timeline.tracks.append(track)
    
    for ts in candidate_timestamps:
        print(f"\nğŸ” æ­£åœ¨åˆ†æç¬¬ {ts} ç§’çš„ç”»é¢...")
        
        # è°ƒç”¨ AI å†³ç­–
        best_cam_idx = get_best_camera_ai(ts, user_prompt)
        print(f"ğŸ¤– AI å†³å®šé€‰ç”¨: æœºä½ {best_cam_idx}")
        
        # å†™å…¥å‰ªè¾‘è¡¨
        file_name = layout["mapping"][best_cam_idx]["file"]
        media_ref = otio.schema.ExternalReference(target_url=os.path.join(DATA_DIR, file_name))
        
        clip = otio.schema.Clip(
            name=f"Cut_{ts}s_Cam{best_cam_idx}",
            media_reference=media_ref,
            source_range=otio.opentime.TimeRange(
                start_time=otio.opentime.RationalTime(ts * 30, 30),
                duration=otio.opentime.RationalTime(30, 30) # å‰ªè¾‘ 1 ç§’
            )
        )
        track.append(clip)

    # ä¿å­˜ç»“æœ
    output_path = os.path.join(BASE_DIR, "timeline.otio")
    otio.adapters.write_to_file(timeline, output_path)
    print(f"\nâœ… å‰ªè¾‘å†³ç­–è¡¨å·²ç”Ÿæˆ: {output_path}")
    print("ä¸‹ä¸€æ­¥: è¿è¡Œ 04_render_final_video.py åˆæˆè§†é¢‘")

if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šæ‰¾ä¸€ä¸ªæ‰£ç¯®åŠ¨ä½œ
    run_pipeline("Find the clearest view of the player slam dunking.")